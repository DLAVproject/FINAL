{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "073886f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import tensorflow as tf\n",
    "import core.utils as utils\n",
    "from tensorflow.python.saved_model import tag_constants\n",
    "from core.config import cfg\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from deep_sort import preprocessing, nn_matching\n",
    "from deep_sort.detection import Detection\n",
    "from deep_sort.tracker import Tracker\n",
    "from tools import generate_detections as gdet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c46227c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definition of the parameters\n",
    "max_cosine_distance = 0.4\n",
    "nn_budget = None\n",
    "nms_max_overlap = 1.0\n",
    "counter_reinit = 0\n",
    "iou = 0.45\n",
    "score = 0.5\n",
    "frame_num = 0\n",
    "first_pass = True\n",
    "input_size = 416\n",
    "trigger_id = None\n",
    "\n",
    "# initialize deep sort\n",
    "model_filename = 'model_data/mars-small128.pb'\n",
    "encoder = gdet.create_box_encoder(model_filename, batch_size=1)\n",
    "# calculate cosine distance metric\n",
    "metric = nn_matching.NearestNeighborDistanceMetric(\"cosine\", max_cosine_distance, nn_budget)\n",
    "# initialize tracker\n",
    "tracker = Tracker(metric)\n",
    "\n",
    "# load safed model\n",
    "saved_model_loaded = tf.saved_model.load('./checkpoints/yolov4-416', tags=[tag_constants.SERVING])\n",
    "infer = saved_model_loaded.signatures['serving_default']\n",
    "\n",
    "# not sure if maybe helpful on GPU\n",
    "#physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "#if len(physical_devices) > 0:\n",
    "#tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "#load configuration for object detector\n",
    "#config = ConfigProto()\n",
    "#config.gpu_options.allow_growth = True\n",
    "#session = InteractiveSession(config=config)\n",
    "\n",
    "# begin video capture\n",
    "vid = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cc02a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reinitialized\n",
      "reinitialized\n",
      "reinitialized\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    return_value, frame = vid.read()\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    frame = cv2.resize(frame, (160, 120), interpolation = cv2.INTER_AREA)\n",
    "\n",
    "    frame_num +=1\n",
    "    \n",
    "    # prepare image for detection process\n",
    "    image_data = cv2.resize(frame, (input_size, input_size))\n",
    "    image_data = image_data / 255.\n",
    "    image_data = image_data[np.newaxis, ...].astype(np.float32)\n",
    "    \n",
    "    # divide into batches\n",
    "    batch_data = tf.constant(image_data)\n",
    "    pred_bbox = infer(batch_data)\n",
    "    for key, value in pred_bbox.items():\n",
    "        boxes = value[:, :, 0:4]\n",
    "        pred_conf = value[:, :, 4:]\n",
    "\n",
    "    # predict bounding boxes of all objects in frame\n",
    "    boxes, scores, classes, valid_detections = tf.image.combined_non_max_suppression(\n",
    "        boxes=tf.reshape(boxes, (tf.shape(boxes)[0], -1, 1, 4)),\n",
    "        scores=tf.reshape(\n",
    "            pred_conf, (tf.shape(pred_conf)[0], -1, tf.shape(pred_conf)[-1])),\n",
    "        max_output_size_per_class=50,\n",
    "        max_total_size=50,\n",
    "        iou_threshold=0.45,\n",
    "        score_threshold=0.5\n",
    "    )\n",
    "\n",
    "    # reinitialization when camera is blocked for several seconds\n",
    "    if valid_detections[0] == 0:\n",
    "        counter_reinit += 1\n",
    "        if counter_reinit >= 61:\n",
    "            print('reinitialized')\n",
    "            first_pass = True\n",
    "            counter_reinit = 0\n",
    "\n",
    "    # convert data to numpy arrays and slice out unused elements\n",
    "    num_objects = valid_detections.numpy()[0]\n",
    "    bboxes = boxes.numpy()[0]\n",
    "    bboxes = bboxes[0:int(num_objects)]\n",
    "    scores = scores.numpy()[0]\n",
    "    scores = scores[0:int(num_objects)]\n",
    "    classes = classes.numpy()[0]\n",
    "    classes = classes[0:int(num_objects)]\n",
    "\n",
    "    # format bounding boxes from normalized ymin, xmin, ymax, xmax ---> xmin, ymin, width, height\n",
    "    original_h, original_w, _ = frame.shape\n",
    "    bboxes = utils.format_boxes(bboxes, original_h, original_w)\n",
    "\n",
    "    # store all predictions in one parameter for simplicity when calling functions\n",
    "    pred_bbox = [bboxes, scores, classes, num_objects]\n",
    "\n",
    "    # read in all class names from config \n",
    "    class_names = utils.read_class_names(cfg.YOLO.CLASSES)\n",
    "    allowed_classes = ['person']\n",
    "\n",
    "    # loop through objects and use class index to get class name, allow only humans to be tracked\n",
    "    names = []\n",
    "    deleted_indx = []\n",
    "    for i in range(num_objects):\n",
    "        class_indx = int(classes[i])\n",
    "        class_name = class_names[class_indx]\n",
    "        if class_name not in allowed_classes:\n",
    "            deleted_indx.append(i)\n",
    "        else:\n",
    "            names.append(class_name)\n",
    "    names = np.array(names)\n",
    "\n",
    "    # delete detections that are not in allowed_classes\n",
    "    bboxes = np.delete(bboxes, deleted_indx, axis=0)\n",
    "    scores = np.delete(scores, deleted_indx, axis=0)\n",
    "\n",
    "    # encode yolo detections and feed to tracker\n",
    "    features = encoder(frame, bboxes)\n",
    "    detections = [Detection(bbox, score, class_name, feature) for bbox, score, class_name, feature in zip(bboxes, scores, names, features)]\n",
    "\n",
    "    # run non-maxima supression\n",
    "    boxs = np.array([d.tlwh for d in detections])\n",
    "    scores = np.array([d.confidence for d in detections])\n",
    "    classes = np.array([d.class_name for d in detections])\n",
    "    indices = preprocessing.non_max_suppression(boxs, classes, nms_max_overlap, scores)\n",
    "    detections = [detections[i] for i in indices]       \n",
    "\n",
    "    # call the tracker\n",
    "    tracker.predict()\n",
    "    tracker.update(detections)\n",
    "\n",
    "    # update tracks\n",
    "    for track in tracker.tracks:\n",
    "        if not track.is_confirmed() or track.time_since_update > 1:\n",
    "            continue \n",
    "\n",
    "        bbox = track.to_tlbr()\n",
    "        class_name = track.get_class()\n",
    "        \n",
    "        # initialize triggered person\n",
    "        if first_pass == True:\n",
    "            trigger_id = track.track_id\n",
    "            first_pass = False\n",
    "        \n",
    "        # show only triggered person in frame\n",
    "        if track.track_id == trigger_id:\n",
    "            cv2.rectangle(frame, (int(bbox[0]), int(bbox[1])), (int(bbox[2]), int(bbox[3])), (255,0,0), 2)\n",
    "            #cv2.rectangle(frame, (int(bbox[0]), int(bbox[1]-30)), (int(bbox[0])+(len(class_name)+len(str(track.track_id)))*17, int(bbox[1])), color, -1)\n",
    "            #cv2.putText(frame, class_name + \"-\" + str(track.track_id),(int(bbox[0]), int(bbox[1]-10)),0, 0.75, (255,255,255),2)\n",
    "\n",
    "    # prepare print \n",
    "    result = np.asarray(frame)\n",
    "    result = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    cv2.imshow(\"Output Video\", result)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75ba4de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()\n",
    "vid.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca342b5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bac35b1da89963a84e831f1e7ac9d5013744a77e967380d6e4824954f258b8e9"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
